{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analyse met Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introductie\n",
    "\n",
    "Python wordt steeds populairder voor data-analyse. Dit komt voornamelijk door de grote ontwikkeling de afgelopen paar jaar ivan paketten die het doen van data-analyse in en met Python makkelijker maken, waaronder:\n",
    "* **NumPy** voor numerieke bewerkingen en mathematische functies\n",
    "* **pandas** voor het werken met tabulaire data\n",
    "* **Matplotlib** voor het creëren van 2D grafische visualisaties\n",
    "* ** Seaborn** uitbreiding op Matplotlib\n",
    "* **Jupyter notebook** webapplicatie voor het documenteren van data-analyse projecten  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"https://r4ds.had.co.nz/diagrams/data-science-explore.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "Image(url= \"https://r4ds.had.co.nz/diagrams/data-science-explore.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deze tutorial/workshop is opgebouwd uit de volgende onderdelen.\n",
    "1. Creëren, inlezen en opslaan van gegevens\n",
    "2. Het leren kennen van de dataset\n",
    "3. Het verwerken en opschonen van gegevens\n",
    "4. Exploratieve data analyse en visualisatie\n",
    "\n",
    "Per onderdeel behandel ik in het kort de basisprincipes van de belangrijktste stappen in de data analyse, waarin je de meest gebruikte methoden en functies leert toe te passen aan de hand van een aantal datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maar voordat we beginnen moeten we eerst de pakketten **`numpy`** en **`pandas`** importeren. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Creëren, inlezen en opslaan van gegevens\n",
    "Ruwe data worden meestal opgeslagen in de vorm van tabellen, oftewel een reeks van rijen en kolommen, waarin de kolommen de variabelen presenteren en de kolommen de individuele observaties. De twee krachtigste objecten in het `pandas` pakket om met tabellen te werken zijn `Series` en de `DataFrame`. \n",
    "Laten we eerst is kijken naar het `Series`-object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het voordeel van een panda-Series object is dat je de index ook een waarde kan meegeven en het maakt niet uit welk data-type dat is. Je kunt het je voorstellen als het geven van een naam aan de observaties in een dataset (de rijen van een tabel). Dus als we kijken naar het vorige voorbeeld dan wordt het commando van een panda-series object dus als volgt: `pd.Series([data], index=index)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Maar je kunt `Series` ook opvatten als een speciaal soort Python *dictionary*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu naar de **Dataframe**. Dit is eigenlijk een **Series**, maar dan niet 1-dimensionaal, maar 2-dimensionaal. Naast dat het een `index` attribuut heeft voor de rijen, heeft het ook een `index` attribuut voor de kolommen. Op deze manier hebben we dus toegang tot alle waarden in de data via de rij-index en de kolom-index. Een pandas-dataframe kan op verschillende manieren worden gecreëerd. Ik laat hieronder twee manieren zien:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Vanuit een bestaande pandas-Series\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-02424b600da4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Vanuit een dictionary van Series objecten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m hoofdsteden = pd.Series([\"Groningen\", \"Leeuwarden\", \"Assen\", \"Zwolle\", \"Lelystad\", \"Haarlem\", \n\u001b[0m\u001b[0;32m      4\u001b[0m                          \"Den Haag\", \"Utrecht\", \"Arnhem\", \"Den Bosch\", \"Middelburg\", \"Maastricht\"])\n\u001b[0;32m      5\u001b[0m \u001b[0mprovincies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"GR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"DR\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"OV\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"FL\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NH\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ZH\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"UT\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GD\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"NB\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"ZL\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Li\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "## Vanuit een dictionary van Series objecten\n",
    "\n",
    "hoofdsteden = pd.Series([\"Groningen\", \"Leeuwarden\", \"Assen\", \"Zwolle\", \"Lelystad\", \"Haarlem\", \n",
    "                         \"Den Haag\", \"Utrecht\", \"Arnhem\", \"Den Bosch\", \"Middelburg\", \"Maastricht\"])\n",
    "provincies = pd.Series([\"GR\", \"FR\", \"DR\", \"OV\", \"FL\", \"NH\", \"ZH\", \"UT\", \"GD\", \"NB\", \"ZL\", \"Li\"])\n",
    "inwoners = pd.Series([195839, 96174, 67153, 122737, 76081, 154352, 507611, 324723, 150354, 143373, 54687, 121317])\n",
    "specialiteit = pd.Series([\"Grunneger Kouke\", \"Fryske dúmkes\", \"Knieperties\", \"Zwollse Balletjes\", \n",
    "                          \"Lekkerding\", \"Haarlemmer Halletjes\", \"Haagsche Kakker\", \"Tekantjes\", \n",
    "                          \"Arnhemse meisjes\", \"Bossche Bol\", \"Zeeuwse Bolus\", \"Limburgse Vlaai\"])\n",
    "\n",
    "df_hoofdsteden = pd.DataFrame({'Hoofdsteden': hoofdsteden, 'Provincie':provincies, \n",
    "                               'Inwonertal':inwoners, 'Lekkernij':specialiteit})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#990000\">Opdracht 1\n",
    "<font color=\"#990000\"> \n",
    "Creëer hieronder een dataframe met de volgende vorm: <br> \n",
    "\n",
    "| Fruit  |Aantal|Kleur |\n",
    "| ------ |:---:|:------|\n",
    "| Banaan |3    |geel   |\n",
    "| Appel  |5    |rood   |\n",
    "| Peer   |2    |groen  | \n",
    "| Bosbes |50   |blauw  |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>Meestal zul je werken aan bestaande data. Deze kunnen zijn opgeslagen in verschillende type bestanden. Het pandas-pakket kent verschillende functies die het makkelijk maken om tabulaire data in Python in te laden als een DataFrame object. De functies die je het meest zult gebruiken zijn:\n",
    "* **read_table** - voor het inlezen van data met tabs als scheidingsteken\n",
    "* **read_csv**   - voor het inlezen van data met komma's als schedingsteken\n",
    "\n",
    "Hieronder ga ik een csv-bestand inlezen. Dit bestand heeft de naam *titanic.csv*. Zorg ervoor dat je het bestand in de bestandsmap heb staan van waaruit je werkt. Anders kan jupyter notebook het bestand niet vinden.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In het voorbeeld hierboven staat het argument `sep` voor *separator*. We hoeven in dit geval niet specifiek `sep=\",\"` door te geven omdat de komma de defaultwaarde is. Maar het komt ook voor dat gegevens worden gescheiden door andere tekens, bijvoorbeeld een tab `'\\t'` of een punt-komma `';'`. Dan moet dit wel specifiek worden doorgegeven aan het argument `sep`. De functie **`read_csv`** heeft nog veel meer additionele argumenten die je kunt gebruiken. Handig zijn bijvoorbeeld de argumenten voor het overslaan van rijen, het benoemen van kolommen of het verwijderen van `NaN`s (lege waarden). Een volledige lijst vind je in de documentatie: https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#990000\">Opdracht 2\n",
    "<font color=\"#990000\"> In jullie werkmap bevinden zich als het goed is ook de bestanden **Weerstations.csv** en **Temperatuur_2017.csv**. Lees deze bestanden in met de methode **read_csv**. Maar let op dat de bestanden een **;** gebruiken als scheidingsteken. <br> Verderop in deze tutorial gaan we naar deze datasets kijken, dus print ze nog niet naar de console."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weerstations ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_2017 ="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> Het is ook makkelijk om je data weg te schrijven naar een bestand. Dit kan met de functie **`df.to_csv`**. Laten we hiervoor de dataframe nemen met de provinciehoofdsteden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Als het goed is bevind er zich nu een bestand met de naam *Provinciehoofdsteden* in de bestandsmap waarin je nu werkt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#990000\">Opdracht 3\n",
    "<font color=\"#990000\"> In opdracht 1 heb je een dataframe gemaakt. Schrijf deze dataframe nu weg naar een csv-bestand. Noem dit bestand \"Mijn_Dataframe.csv\"\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br> \n",
    "## 2. Het leren kennen van de dataset\n",
    "Een belangrijke stap nadat je een dataset hebt ingeladen, is het leren kennen ervan. Je wilt bijvoorbeeld weten wat de dimensies zijn, dat wil zeggen uit hoeveel rijen en kolommen de dataset bestaat. Ook is het belangrijk om te weten wat het datatype is van elke kolom en wat de betekenis is van elke variabele. Ook komt het vaak voor dat er gegevens missen en wil je weten hoeveel datapunten geen waardes hebben en waar zich die bevinden in de dataset. Hieronder laat ik een greep zien uit de functies en methoden die je kunt toepassen op je dataset om daarachter te komen en zo een goed beeld te krijgen waar je mee te maken hebt. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het eerste wat we gaan doen is het bekijken van onze dataset. Hiervoor kunnen we een aantal functies toepassen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laat de eerste 6 rijen van de dataset zien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Laat de laatste 6 rijen van de dataset zien\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produceert een tuple van de dimensies van de dataframe\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectie van de shape-tuple (aantal rijen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selectie van de shape-tuple (aantal kolommen)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retourneert een index-lijst van de kolomlabels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Toont een overzicht van de data-types van alle variabelen in de dataset (kolommen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Geheel overzicht van het aantal 'niet-ontbrekende' waardes per variabele en het datatype\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Count van alle ontbrekende waardes (NaN) per variabele\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#990000\">Opdracht 4\n",
    "<font color=\"#990000\"> Pas nu bovenstaande methodes toe op de twee dataframes die je eerder hebt ingeladen (temp2017 en weerstations). Deze datasets bevatten de gemiddelde, minimum en maxium dagtemperaturen over 2017 van alle weerstations in Nederland en de tweede dataset bevat informatie over deze weerstations. De data is afkomstig van het KNMI.\n",
    "<br>Beantwoord voor jezelf de volgende vragen: \n",
    "* Uit hoeveel rijen en kolommen bestaan de datasets?\n",
    "* Wat zijn de datatypes van de variabelen?\n",
    "* Zijn er ontbrekende waardes en hoeveel?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vaak willen we alleen bepaalde kolommen selecteren. Dat wordt ook wel indexeren genoemd. Pandas biedt veel manieren om te indexeren en er is soms dan ook wat verwarring over. Ik laat jullie hieronder de 2 meest gangbare manier zien. De eerste is op basis van het selecteren op label (kolom- of rij-naam). Dit wordt ook wel expliciet indexeren genoemd en hiervoor gebruik je de `.loc[]` methode. De tweede is op basis van het selecteren op rij- of kolom-index. Dit wordt ook wel impliciet indexeren genoemd en hiervoor gebruik je de `.iloc[]` methode. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Een enkele kolom selecteren op basis van kolom-naam:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Een enkele kolom selecteren op basis van kolom-index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Meerder opeenvolgende kolommen selecteren op basis van kolom-naam\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben deze dataset geen naam meegegeven voor de rijen, dus we kunnen rijen alleen *impliciet* indexeren:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Een enkele rij selecteren op basis van rij-index:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecteren van meerdere rijen\n",
    "                                         # let wel op dat de selectie gaat van begin-index tot eind-index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We kunnen ook een selectie maken op basis van een bepaalde conditie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecteert alle pasagiers die in de eerse klas reisden\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecteert alle mannelijke passagiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Selecteert alleen alle overlevende mannen\n",
    " ## Hier gebruik ik de dot-notatie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dus van de 577 mannelijke pasagiers van de Titanic hebben maar 109 mannen de ramp overleefd!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## <font color=\"#990000\">Opdracht 5\n",
    "<font color=\"#990000\"> \n",
    "* Vanuit de titanic dataset, selecteer de kolom met de naam \"fare\" \n",
    "* Vanuit de titanic dataset, selecteer rij 121\n",
    "* Selecteer nu alle vrouwelijke pasagiers. Hoeveel vrouwen waren er aan boord van de Titanic?\n",
    "* Hoeveel vrouwen hebben de ramp overleefd?\n",
    "    \n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Het verwerken en opschonen van gegevens\n",
    "Een data-analist spendeerd het grootste gedeelte van zijn/haar tijd aan het opschonen van gegevens. Hetis dus belangrijk om deze stap van het data analyse proces te beheersen. Een aantal taken die vaak terugkomen zijn:\n",
    "\n",
    "* Het verwijderen van onnodige kolommen\n",
    "* Het hernoemen van kolommen met herkenbare labels\n",
    "* Het samenvoegen van tabellen op basis van een identieke *key*\n",
    "* Het opsporen en verwijderen van ontbrekende waarden\n",
    "\n",
    "Voor dit onderdeel gaan we met opnieuw werken met de twee datasets van het KNMI. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "weerstations = pd.read_csv(\"Weerstations.csv\", sep=\";\")\n",
    "temp2017 = pd.read_csv(\"Temperatuur_2017.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Het eerste wat we gaan doen is de kolommen die we niet nodig hebben voor onze analyse verwijderen uit onze dataset. In dit geval zijn dat de kolommen LON(east), LAT(north) en ALT(m) in de weerstation-dataset. Dit gaan we doen door middel van de `.drop` methode. Als argument nemen we de index van de kolommen die we willen verwijderen. Het tweede argument is `axis=1` waarmee we aangeven dat we kolommen willen verwijderen (voor het verwijderen van rijen staat de default op `axis=0`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#990000\">Opdracht 6\n",
    "<font color=\"#990000\"> Nu hebben we nog steeds twee kolommen die dezelfde informatie bevatten. Verwijder de kolom 'CODE' uit de weerstation-dataset. <br>Gebruik hiervoor de **.drop** methode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Nu kunnen we de twee datasets samenvoegen op basis van de kolom **STN** die in beide datasets voorkomt. We gebruiken hiervoor de `pd.merge` methode vanuit het pandas pakket. Deze methode herkent de overeenkomstige kolom automatisch en gebruikt de kolom als 'key' om de twee datasets bij elkaar te voegen. Het resultaat is een nieuwe dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We hebben nu één dataset. Verolgens is het tijd om betere labels te maken voor de kolommen, zodat de betekenis ervan duidelijker wordt. We maken eerst een lijst met de nieuwe labels en daarna vervangen we de oude labels door middel van de methode `.columns`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We zijn al een heel eind zo. Maar het zal je niet ontgaan zijn dat bij de laatste drie kolommen die de temperatuurmetingen bevatten het woordje **NaN** staat. Dit betekent letterlijk *Not a Number* en is eigenlijk een lege waarde. Dit komt vaak voor in de data analyse en betekent vaak dat er voor deze specifieke datapunten geen meting is gedaan. De volgende stap is dan ook deze NaN-waardes te inspecteren en omdat we in dit geval alleen geïnteresseerd zijn in echte metingen gaan we de NaN's uit onze dataset verwijderen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hoeveel NaN's zijn er?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Het verwijderen van de rijen die NaN's bevatten\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu gaan we wat zaken combineren. Ik ben bijvoorbeeld geïnteresseerd in de maximum-temperatuur en wil graag wanneer dat was en waar. Ik ga eerst de kolommen verwijderen waar ik niet in geïnteresseerd ben en sla de resterende kolommen op in een nieuwe dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_max = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nu kunnen we de functie `.sort()` gebruiken om de data te sorteren op maximum temperatuur. Dit kan op verschillende manieren."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Via de dot-notatie. Retourneert een pandas series\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Alternatieve manier via de kolom-label. Resultaat is hetzlefde als hierboven.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# De hele dataframe sorteren op basis van een kolom\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color=\"#990000\">Opdracht 7\n",
    "<font color=\"#990000\"> \n",
    "* Onderzoek wat de minimum-temperatuur was in 2017 en waar en wanneer dat was.\n",
    "* De Titanic-dataset heeft aardig wat kolommen met dezelfde informatie (bijvoorbeeld de kolommen 'sex' en 'who'). Verwijder naar eigen inzicht dubbele kolommen en sla op als een nieuwe dataset met de naam **titanic2**. Hernoem de kolommen naar eigen inzicht met nieuwe labels. (Bijvoorbeeld 'Leeftijd' voor de kolom 'Age'.) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "## 4. Exploratieve data analyse en visualisatie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Op het moment dat we onze data hebben opgeschoond en geïnspecteerd kunnen we gaan beginnen met het exploratieve deel. Dit ga ik opnieuw illustreren aan de hand van de Titanic dataset. We hebben al gezien dat deze dataset veel informatie bevat over de befaamde tocht die eindigde in een catastrofe. We willen graag wat meer inzicht krijgen. Dit gaan we doen aan de hand van wat statistiek en draaitabellen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ik heb de originele titanic-dataset wat opgeschoond. Dat wil zeggen, ik heb kolommen met dubbele informatie verwijderd en de kolommen een betekenisvolle naam in het nederlands gegeven. Deze nieuwe dataframe heb ik opgeslagen als **titanic2**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic2 = pd.read_csv(\"Titanic2.csv\", sep=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Handige methode om een totaalbeeld te krijgen van de data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dit kunnen we ook per variabele bekijken\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "## De som van alle overlevenden:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ik ben zelf erg nieuwsgierig naar de relatie tussen de overlevingsstatus en sexe. Dit kunnen we doen met de methode `groupby`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dat betekent dat drie-kwart van de vrouwen het hebben overleefd en minder dan een-vijfde van de mannen! <br>\n",
    "Ik zou verder graag willen weten of er ook nog een relatie bestaat met de klasse. Maar de methode `groupby` wordt dan te ingewikkeld om te gebruiken voor het toevoegen van meer lagen. Gelukkig heeft pandas ook nog de methode `pivot_table` die veel geschikter is voor het werken met multi-dimensionale aggregaties:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dit maakt het gelijk duidelijk dat meer dan 90% van de vrouwen in de eerste en tweede klassen de ramp hebben overleefd, terwijl de overlevingskansen voor de mannen in de tweede en derde klassen extreem laag waren. <br>\n",
    "Laten we er nog een laag bij doen, die voor leeftijd en om de scheiding te maken tussen kinderen en volwassenen gebruiken we de `pd.cut` functie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Laten we dit gaan visualiseren. Hiervoor moeten we nog twee andere pakketten importeren, namelijk **matplotlib** en **seaborn**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overlevingspercentages per sexe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Overlevingspercentages per klasse\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "## Histogram van de leeftijdsverdeling van de passagiers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De leeftijdsdistributie voor overlevenden en niet-overlevenden is vrijwel gelijk. Wat vooral opvalt is dat de grafiek van de overlevenden uit twee pieken bestaat. Dit betekent dat een groter aantal kinderen de ramp hebben overleefd. Wel moeten we een kant-tekening zetten bij deze distributie, want zoals hierboven aangegeven, van 177 passagiers is de leeftijd niet bekend en dit heeft zonder twijfel invloed op de distributie. <br>\n",
    "Laten we eenzelfde distributie maken van de prijs van een ticket."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Een schokkend resultaat. Er is duidelijk een verschil in ticketprijs voor overlevenden en niet-overlevenden!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
